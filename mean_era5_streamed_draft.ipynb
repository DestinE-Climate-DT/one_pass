{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-pass algorithm of the mean using ERA5 data\n",
    "\n",
    "This script is the first draft implementation of the one-pass algorithm for the mean statistic. It uses ERA5 data of the horizontal 100m wind at 1 hourly intervals and calculates the daily mean. The ERA5 data is accessed via a moving window in a loop. The output is saved as a netCDF. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "from time import perf_counter\n",
    "import cProfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the future, the input parameters, such as the variable (e.g. temp, precipitation) and frequency of statistic will need to be paramaterised based on user requirements and the statistics provided as functions. For now, picking hourly u100m data, from monthly data files. The result at the end of the script will be one netCDF file with all the daily means across all the months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# timing to check preformance \n",
    "start = time.perf_counter()\n",
    "\n",
    "# creating list of era5 data files (stored in files containing 1 month of data)\n",
    "filePath = \"/esarchive/recon/ecmwf/era5/1hourly/u100m/\"\n",
    "fileList = sorted(os.listdir(filePath)) # sorted to get them into the correct order \n",
    "nFiles = np.size(fileList) # finding number of files (also number of months)\n",
    "\n",
    "# mean frequency required, this should be able to change \n",
    "meanFreq = \"daily\"\n",
    "\n",
    "# initalising variables \n",
    "countHours = 0 # stores the number of TOTAL data points or windows examined (in this case hourly data), this needs to be cumlative for each file\n",
    "countDays = 0 # this stores total days counted used for placing daily means into final array\n",
    "\n",
    "# going to run though all montly files so the loop opens each file \n",
    "# this can run through range(0, nFiles) but just doing 0 to 1 for speed\n",
    "for k in range(0, 1):\n",
    "\n",
    "    fileName = filePath + fileList[k]\n",
    "    ds = xr.open_dataset(fileName, engine = \"netcdf4\") # open dataset \n",
    "\n",
    "    if (k == 0):\n",
    "        # initalising daily mean array, starting initial dimension as 0 as don't know how many days (simulating real GSV)\n",
    "        # only need to initalise once (hence if loop) and nee to start index as 0 not 1, otherwise end up with empty index \n",
    "        # might be faster to take this outside of the main loop and just open the first dataset outside main loop\n",
    "        meanDaily = np.zeros((0, np.size(ds.lat), np.size(ds.lon))) # better to use empty or zeros? \n",
    "        timeDaily = pd.DatetimeIndex([]) # initalising time loop \n",
    "        # can initialise the array with known number of days but probably won't know that while streaming\n",
    "        #meanDaily = np.zeros((nDays, np.size(ds.lat), np.size(ds.lon))) # initalising daily mean array \n",
    "\n",
    "\n",
    "    # extracting time array from file, calling timeData not time as time is name of python module \n",
    "    timeData = sorted(ds.time.data)\n",
    "\n",
    "    # checking that the spacing of the data is indeed hours\n",
    "    timeDiff = timeData[1] - timeData[0]\n",
    "    #hours = timeDiff.astype('timedelta64[h]')\n",
    "    hours = timeDiff / np.timedelta64(1, 'h') # this should be 1 \n",
    "\n",
    "    # knowning time difference is hours, want to know how many hours \n",
    "    nHours = np.size(timeData)\n",
    "\n",
    "    # want to check how many days in the file \n",
    "    # this is an easy way but should find a more robust way, maybe the commented out method below?\n",
    "    nDays = int(nHours / 24)\n",
    "\n",
    "    #daysDiff = time[-1] - time[0] # whole time diff of data file \n",
    "    #days = daysDiff.astype('timedelta64[D]')\n",
    "    #nDays = int(days / np.timedelta64(1, 'D')) # converts from timedelta64 into integer value\n",
    "\n",
    "    # this exracts all the timestamps of each data point in hours \n",
    "    timeStamp = [pd.to_datetime(x) for x in ds.time.values]\n",
    "    # converts to daily timestamp \n",
    "    timeStampDaily = pd.date_range(timeStamp[0], freq = \"D\", periods = nDays)\n",
    "\n",
    "\n",
    "    # for now asking for daily mean with hourly data (will need to create a loop of options here)\n",
    "    if (meanFreq == \"daily\" and hours == 1):\n",
    "        \n",
    "        for i in range(0, nDays): # the way python indexs having range(0, 20) goes 0 to 19. Last number not included\n",
    "\n",
    "            mean = 0.0 # initalising mean for that day \n",
    "            \n",
    "            for j in range(0, 24): # always 24 hours in a day, again range will go 0 to 23, what about day light savings? find more robust way\n",
    "                \n",
    "                timeSlice = ds.u100m.isel(time=slice(countHours,(countHours+1))) # slice(start, stop, step), extract 'moving window' which is hourly data\n",
    "                timeSlice = np.squeeze(timeSlice) # removing the redundant 1 dimension \n",
    "                \n",
    "                countHours = countHours + 1 # update frequency count (this HAS TO BE the loop + 1 because python index starts at 0)\n",
    "                \n",
    "                # now to update the acutal mean \n",
    "\n",
    "                # this could be written on two lines (as shown below) but need to store both mean and meanOld:            \n",
    "                #mean = meanOld + (timeSlice-meanOld)/(j+1)\n",
    "                #meanOld = mean\n",
    "\n",
    "                mean += (timeSlice-mean)/(j+1) # as looking at daily mean the denominator must range between 1 to 24 (hence j+1)\n",
    "\n",
    "            # now in daily array, adding daily mean to data. Can only use top line if array size predefined.\n",
    "            #meanDaily[countDays,:,:] = mean\n",
    "            meanDaily = np.insert(meanDaily, countDays,  mean, axis = 0)\n",
    "            timeDaily = pd.DatetimeIndex.insert(timeDaily, countDays, timeStampDaily[i])\n",
    "            countDays = countDays + 1\n",
    "\n",
    "\n",
    "# checking preformance time \n",
    "end = time.perf_counter()\n",
    "elapsed = end-start\n",
    "elapsed\n",
    "\n",
    "# Now creating new dataset for the updated files\n",
    "# Copying the latitude and longitude data as this hasn't changed, with new time dimension based on daily time\n",
    "\n",
    "dm = xr.Dataset(\n",
    "    data_vars = dict(\n",
    "        dailyMean_u100 = ([\"time\",\"lat\",\"lon\"], meanDaily),                            \n",
    "    ),\n",
    "    coords = dict(\n",
    "        time = timeDaily,\n",
    "        lon = ([\"lon\"], ds.lon),\n",
    "        lat = ([\"lat\"], ds.lat),\n",
    "    ),\n",
    "    attrs = dict(\n",
    "        description = \"daily means of u100 m wind calculated using one-pass algorithm\",\n",
    "        #attrs = ds.attrs,\n",
    "    ),\n",
    ")\n",
    "   \n",
    "# saving the new dataArray to netCDF \n",
    "\n",
    "path = \"/esarchive/scratch/kgrayson/git/onepass_development/daily_means_era5_u100m.nc\"\n",
    "dm.to_netcdf(path, mode = 'w', format = \"NETCDF4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now comparing the calculated mean against the mean calculated using numpy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.DataArray 'u100m' ()>\n",
       "array(9.53674316e-06)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking by taking mean across first day using np.mean. This part is not in the python script. There is an average diff of 10^-7\n",
    "# this could probably be vectorised by looping through the days for now \n",
    "\n",
    "# initialising array \n",
    "avgDiff = np.zeros(nDays)\n",
    "\n",
    "for kl in range(0, nDays):\n",
    "    hourCount = kl*24\n",
    "    hourCountNext = (kl+1)*24\n",
    "    # extracting 24 hours of data from the original time series and taking the mean across the hours \n",
    "    a = np.mean(ds.u100m.isel(time = slice(hourCount, hourCountNext)),axis=0)\n",
    "    # taking this np.mean and subtracting the mean calculated from the algorithm \n",
    "    diff = a - np.squeeze(meanDaily[kl,:,:])\n",
    "    # averaging the difference \n",
    "    avgDiff[kl] = np.mean(diff, axis=(0,1))\n",
    "\n",
    "diff24 = np.max(diff)\n",
    "diff24 \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
